import streamlit as st
from openai import OpenAI


def get_openai_client():
    """OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—"""
    return OpenAI(api_key=st.secrets["openai"]["api_key"])


def _get_ai_settings(course_id: str) -> dict:
    """course_settingsã‹ã‚‰AIãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯è¨­å®šã‚’å–å¾—ï¼ˆå¤±æ•—æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰"""
    if not course_id:
        return {}
    try:
        from utils.database import get_course_settings
        s = get_course_settings(course_id) or {}
        return s.get("ai_feedback", {})
    except Exception:
        return {}


def _get_speaking_weights(course_id: str, task_type: str, assignment_id: str = None) -> dict:
    """ã‚¹ãƒ”ãƒ¼ã‚­ãƒ³ã‚°è©•ä¾¡ã‚¦ã‚§ã‚¤ãƒˆã‚’å–å¾—"""
    if not course_id:
        return {}
    try:
        from utils.database import get_course_settings
        s = get_course_settings(course_id) or {}

        # èª²é¡Œå€‹åˆ¥è¨­å®šã‚’å„ªå…ˆ
        if assignment_id:
            rubric = s.get("assignment_rubrics", {}).get(assignment_id, {})
            if rubric.get("weights"):
                return rubric["weights"]

        sw = s.get("speaking_weights", {})
        return sw.get(task_type, {})
    except Exception:
        return {}


def _build_feedback_language_instruction(lang: str) -> str:
    if lang == "english":
        return "Provide all feedback in English only."
    elif lang == "bilingual":
        return "Provide all feedback in both English and Japanese. Format: English text / æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆ"
    else:  # japanese (default)
        return "ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¯ã™ã¹ã¦æ—¥æœ¬èªã§æä¾›ã—ã¦ãã ã•ã„ã€‚"


def _build_feedback_detail_instruction(detail: str) -> str:
    if detail == "brief":
        return "ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¯å„é …ç›®1ã€œ2æ–‡ã§ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚"
    elif detail == "detailed":
        return "ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¯å„é …ç›®ã«ã¤ã„ã¦å…·ä½“ä¾‹ã‚’äº¤ãˆã¦è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
    else:  # standard
        return "ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¯å„é …ç›®3ã€œ5æ–‡ç¨‹åº¦ã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"


def _build_speaking_priority_instruction(priority: str) -> str:
    if priority == "pronunciation_focus":
        return (
            "## è©•ä¾¡ã®é‡ç‚¹æ–¹é‡: ç™ºéŸ³é‡è¦–\n"
            "ç™ºéŸ³ã®æ­£ç¢ºã•ãƒ»æ˜ç­ã•ã‚’æœ€å„ªå…ˆã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚"
            "æµæš¢ã•ã‚„æ–‡æ³•ã‚ˆã‚Šã‚‚ã€å€‹ã€…ã®éŸ³ãƒ»ã‚¢ã‚¯ã‚»ãƒ³ãƒˆãƒ»ã‚¤ãƒ³ãƒˆãƒãƒ¼ã‚·ãƒ§ãƒ³ã®æ”¹å–„ç‚¹ã‚’å…·ä½“çš„ã«æŒ‡æ‘˜ã—ã¦ãã ã•ã„ã€‚"
        )
    elif priority == "fluency_focus":
        return (
            "## è©•ä¾¡ã®é‡ç‚¹æ–¹é‡: æµæš¢ã•é‡è¦–\n"
            "å³èˆˆã§ã®æµæš¢ã•ã¨ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ç¶™ç¶šæ€§ã‚’æœ€å„ªå…ˆã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚"
            "æ–‡æ³•ãƒŸã‚¹ã‚„ç™ºéŸ³ã‚ˆã‚Šã€æ­¢ã¾ã‚‰ãšè©±ã—ç¶šã‘ã‚‰ã‚Œã¦ã„ã‚‹ã‹ã‚’é‡è¦–ã—ã¦ãã ã•ã„ã€‚"
        )
    elif priority == "communication_focus":
        return (
            "## è©•ä¾¡ã®é‡ç‚¹æ–¹é‡: ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³é‡è¦–\n"
            "æ„æ€ç–é€šã®æˆåŠŸã¨ç©æ¥µçš„ãªã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ„æ¬²ã‚’æœ€å„ªå…ˆã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚"
            "æ–‡æ³•ãƒ»ç™ºéŸ³ã®ãƒŸã‚¹ãŒã‚ã£ã¦ã‚‚ã€ä¼ã‚ã£ã¦ã„ã‚Œã°ç©æ¥µçš„ã«è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚"
        )
    else:  # balanced
        return (
            "## è©•ä¾¡ã®é‡ç‚¹æ–¹é‡: ãƒãƒ©ãƒ³ã‚¹å‹\n"
            "ç™ºéŸ³ãƒ»æµæš¢ã•ãƒ»å†…å®¹ãƒ»ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ„æ¬²ã‚’ãƒãƒ©ãƒ³ã‚¹ã‚ˆãè©•ä¾¡ã—ã¦ãã ã•ã„ã€‚"
        )


def _build_weights_instruction(weights: dict) -> str:
    """ã‚¦ã‚§ã‚¤ãƒˆè¨­å®šã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¤‰æ›"""
    if not weights:
        return ""
    label_map = {
        "pronunciation": "ç™ºéŸ³",
        "prosody": "ãƒ—ãƒ­ã‚½ãƒ‡ã‚£ãƒ¼ï¼ˆã‚¤ãƒ³ãƒˆãƒãƒ¼ã‚·ãƒ§ãƒ³ãƒ»ãƒªã‚ºãƒ ï¼‰",
        "fluency": "æµæš¢ã•",
        "accuracy": "æ­£ç¢ºã•",
        "content": "å†…å®¹",
        "structure": "æ§‹æˆ",
        "vocabulary": "èªå½™",
        "grammar": "æ–‡æ³•",
        "communication": "ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ„æ¬²",
    }
    lines = ["## è©•ä¾¡ã‚¦ã‚§ã‚¤ãƒˆï¼ˆã“ã®é…åˆ†ã§ã‚¹ã‚³ã‚¢ã«é‡ã¿ä»˜ã‘ã—ã¦ãã ã•ã„ï¼‰:"]
    for k, v in weights.items():
        label = label_map.get(k, k)
        lines.append(f"- {label}: {v}%")
    return "\n".join(lines)


# ============================================================
# Speakingè©•ä¾¡ï¼ˆgpt_eval.py ãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼‰
# ============================================================

def evaluate_language_use(text, context="speaking",
                          course_id: str = None,
                          task_type: str = "monologue",
                          assignment_id: str = None):
    """
    GPT-4oã§èªå½™ãƒ»æ–‡æ³•ãƒ»å†…å®¹ãƒ»è‡ªç„¶ã•ã‚’è©•ä¾¡ã€‚
    course_idãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆã€course_settingsã®è¨­å®šã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«åæ˜ ã€‚

    å¼•æ•°:
        text          : è©•ä¾¡å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ
        context       : "speaking" / "dialogue" / "read_aloud" ãªã©
        course_id     : ã‚³ãƒ¼ã‚¹IDï¼ˆè¨­å®šåæ˜ ã«ä½¿ç”¨ã€Noneãªã‚‰å¾“æ¥é€šã‚Šï¼‰
        task_type     : "read_aloud" / "monologue" / "dialogue"
        assignment_id : èª²é¡ŒIDï¼ˆèª²é¡Œåˆ¥è¨­å®šã‚’å„ªå…ˆã™ã‚‹å ´åˆï¼‰
    """
    client = get_openai_client()

    # â”€â”€ è¨­å®šå–å¾— â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ai_settings = _get_ai_settings(course_id)
    weights = _get_speaking_weights(course_id, task_type, assignment_id)

    sp_priority   = ai_settings.get("speaking_priority", "balanced")
    fb_lang       = ai_settings.get("feedback_language", "japanese")
    fb_detail     = ai_settings.get("feedback_detail", "standard")
    extra_instr   = ai_settings.get("extra_instruction", "")

    # â”€â”€ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆçµ„ã¿ç«‹ã¦ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    priority_block  = _build_speaking_priority_instruction(sp_priority)
    lang_block      = _build_feedback_language_instruction(fb_lang)
    detail_block    = _build_feedback_detail_instruction(fb_detail)
    weights_block   = _build_weights_instruction(weights)
    extra_block     = f"\n## æ•™å“¡ã‹ã‚‰ã®è¿½åŠ æŒ‡ç¤º:\n{extra_instr}" if extra_instr else ""

    prompt = f"""ã‚ãªãŸã¯ World Englishesï¼ˆä¸–ç•Œã®å¤šæ§˜ãªè‹±èªï¼‰ã«ç²¾é€šã—ãŸè‹±èªæ•™è‚²ã®å°‚é–€å®¶ã§ã™ã€‚

## é‡è¦ãªå‰æ:
- è‹±èªã«ã¯ã€Œæ­£ã—ã„ã€å˜ä¸€ã®å½¢ã¯ã‚ã‚Šã¾ã›ã‚“
- è©•ä¾¡ã®åŸºæº–ã¯ã€Œãƒã‚¤ãƒ†ã‚£ãƒ–ã‚‰ã—ã•ã€ã§ã¯ãªãã€Œå›½éš›çš„ãªé€šã˜ã‚„ã™ã•ï¼ˆInternational Intelligibilityï¼‰ã€ã§ã™
- å­¦ç¿’è€…ã®åŠªåŠ›ã‚’èªã‚ã€åŠ±ã¾ã—ã‚’å«ã‚ã‚‹

{priority_block}
{weights_block}
{extra_block}

## ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯è¨€èª: {lang_block}
## ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯è©³ç´°åº¦: {detail_block}

## åˆ†æå¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ:
{text}

## ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {context} / ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—: {task_type}

## è©•ä¾¡é …ç›®ã¨å‡ºåŠ›å½¢å¼ï¼ˆJSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼‰:

{{
    "scores": {{
        "vocabulary": <0-100ã®æ•´æ•°: èªå½™ã®é©åˆ‡ã•ãƒ»å¤šæ§˜æ€§>,
        "grammar": <0-100ã®æ•´æ•°: æ–‡æ³•ã®æ­£ç¢ºã•>,
        "content": <0-100ã®æ•´æ•°: å†…å®¹ã®å……å®Ÿåº¦ãƒ»è«–ç†æ€§>,
        "intelligibility": <0-100ã®æ•´æ•°: å›½éš›çš„ãªé€šã˜ã‚„ã™ã•>
    }},
    "expression_feedback": [
        {{
            "original": "<åŸæ–‡ã®è©²å½“ç®‡æ‰€>",
            "status": "<acceptable/regional/suggest_alternative>",
            "regions_used": "<ã“ã®è¡¨ç¾ãŒä½¿ã‚ã‚Œã‚‹åœ°åŸŸãƒ»æ–‡è„ˆãŒã‚ã‚Œã°è¨˜è¼‰ã€‚ãªã‘ã‚Œã°null>",
            "note": "<ã“ã®è¡¨ç¾ã«ã¤ã„ã¦ã®èª¬æ˜>",
            "alternatives": [
                {{
                    "expression": "<ä»£æ›¿è¡¨ç¾>",
                    "region": "<ä¸»ã«ä½¿ã‚ã‚Œã‚‹åœ°åŸŸ: American/British/Australian/Internationalç­‰>",
                    "formality": "<formal/neutral/informal>"
                }}
            ],
            "recommendation": "<å­¦ç¿’è€…ã¸ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹>"
        }}
    ],
    "grammar_feedback": [
        {{
            "original": "<åŸæ–‡ã®è©²å½“ç®‡æ‰€>",
            "is_error": <true/false>,
            "is_regional_variant": <true/false>,
            "correction": "<ä¿®æ­£ãŒå¿…è¦ãªå ´åˆã®ä¿®æ­£å¾Œ>",
            "explanation": "<èª¬æ˜>",
            "regions_where_acceptable": "<ã“ã®æ–‡æ³•ãŒè¨±å®¹ã•ã‚Œã‚‹åœ°åŸŸãŒã‚ã‚Œã°è¨˜è¼‰>"
        }}
    ],
    "vocabulary_analysis": {{
        "cefr_level": "<A1/A2/B1/B2/C1>",
        "strengths": "<èªå½™ã®è‰¯ã„ç‚¹>",
        "suggestions": "<ã‚ˆã‚Šå¤šæ§˜ãªèªå½™ã®ææ¡ˆ>",
        "academic_words_used": ["<ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã‚¢ã‚«ãƒ‡ãƒŸãƒƒã‚¯ãªèªå½™>"],
        "colloquial_words_used": ["<ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹å£èªè¡¨ç¾>"]
    }},
    "content_analysis": {{
        "clarity": "<å†…å®¹ã®æ˜ç¢ºã•ã«ã¤ã„ã¦>",
        "organization": "<æ§‹æˆã«ã¤ã„ã¦>",
        "strengths": "<è‰¯ã„ç‚¹>",
        "suggestions": "<æ”¹å–„ææ¡ˆ>"
    }},
    "cultural_notes": [
        {{
            "topic": "<æ–‡åŒ–çš„ã«æ³¨æ„ãŒå¿…è¦ãªãƒˆãƒ”ãƒƒã‚¯>",
            "note": "<èª¬æ˜>"
        }}
    ],
    "overall_feedback": "<ç·åˆçš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ï¼ˆåŠ±ã¾ã—ã‚’å«ã‚ã¦3-4æ–‡ï¼‰>",
    "enhanced_version": {{
        "text": "<å›½éš›çš„ã«é€šã˜ã‚„ã™ã„è‹±èªã«èª¿æ•´ã—ãŸå…¨æ–‡>",
        "changes_made": "<ã©ã®ã‚ˆã†ãªå¤‰æ›´ã‚’åŠ ãˆãŸã‹ã®èª¬æ˜>"
    }}
}}

## åˆ¤æ–­åŸºæº–:
- "acceptable": å›½éš›çš„ã«åºƒãé€šã˜ã‚‹è¡¨ç¾
- "regional": ç‰¹å®šåœ°åŸŸã§ä½¿ã‚ã‚Œã‚‹è¡¨ç¾ï¼ˆé–“é•ã„ã§ã¯ãªã„ï¼‰
- "suggest_alternative": ã‚ˆã‚Šåºƒãé€šã˜ã‚‹è¡¨ç¾ãŒææ¡ˆã§ãã‚‹ã‚‚ã®ï¼ˆã€Œé–“é•ã„ã€ã¨ã¯è¨€ã‚ãªã„ï¼‰

## æ³¨æ„:
- ã€Œé–“é•ã„ã€ã¨ã„ã†è¨€è‘‰ã¯æ¥µåŠ›é¿ã‘ã€ã€Œã‚ˆã‚Šåºƒãé€šã˜ã‚‹è¡¨ç¾ã€ã¨ã„ã†è¨€ã„æ–¹ã‚’ã™ã‚‹
- å­¦ç¿’è€…ã®åŠªåŠ›ã‚’èªã‚ã€åŠ±ã¾ã—ã‚’å«ã‚ã‚‹
"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": (
                    "You are an expert in World Englishes and English language education, "
                    "specializing in helping Japanese EFL learners communicate effectively "
                    "in international contexts. Always respond in valid JSON format. "
                    "Be encouraging while providing specific, actionable feedback."
                )},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            response_format={"type": "json_object"}
        )

        import json
        result = json.loads(response.choices[0].message.content)
        result["success"] = True
        return result

    except Exception as e:
        return {"success": False, "error": str(e)}


# ============================================================
# format_gpt_feedbackï¼ˆå¤‰æ›´ãªã—ãƒ»äº’æ›æ€§ç¶­æŒï¼‰
# ============================================================

def format_gpt_feedback(eval_result):
    """GPTè©•ä¾¡çµæœã‚’Markdownå½¢å¼ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""

    if not eval_result.get("success"):
        return f"âš ï¸ è¨€èªè©•ä¾¡ã‚¨ãƒ©ãƒ¼: {eval_result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}"

    feedback = []
    scores = eval_result.get("scores", {})

    feedback.append("## ğŸ“ è¨€èªä½¿ç”¨ã®è©•ä¾¡")
    feedback.append("")
    feedback.append("| é …ç›® | ã‚¹ã‚³ã‚¢ | èª¬æ˜ |")
    feedback.append("|------|--------|------|")
    feedback.append(f"| èªå½™ | {scores.get('vocabulary', 0)}/100 | èªå½™ã®é©åˆ‡ã•ãƒ»å¤šæ§˜æ€§ |")
    feedback.append(f"| æ–‡æ³• | {scores.get('grammar', 0)}/100 | æ–‡æ³•ã®æ­£ç¢ºã• |")
    feedback.append(f"| å†…å®¹ | {scores.get('content', 0)}/100 | å†…å®¹ã®å……å®Ÿåº¦ãƒ»è«–ç†æ€§ |")
    feedback.append(f"| é€šã˜ã‚„ã™ã• | {scores.get('intelligibility', 0)}/100 | å›½éš›çš„ãªã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã®é€šã˜ã‚„ã™ã• |")
    feedback.append("")

    expressions = eval_result.get("expression_feedback", [])
    if expressions:
        feedback.append("---")
        feedback.append("### ğŸŒ è¡¨ç¾ã«ã¤ã„ã¦ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯")
        feedback.append("")
        feedback.append("â€» è‹±èªã«ã¯å¤šæ§˜ãªå¤‰ç¨®ãŒã‚ã‚Šã¾ã™ã€‚ä»¥ä¸‹ã¯ã€Œé–“é•ã„ã€ã§ã¯ãªãã€å›½éš›çš„ãªã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã®é¸æŠè‚¢ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚")
        feedback.append("")
        for expr in expressions:
            original = expr.get("original", "")
            status = expr.get("status", "")
            icon = "âœ…" if status == "acceptable" else "ğŸŒ" if status == "regional" else "ğŸ’¡"
            status_text = {"acceptable": "å•é¡Œãªã—", "regional": "åœ°åŸŸå·®ã‚ã‚Š"}.get(status, "ä»£æ›¿è¡¨ç¾ã‚ã‚Š")
            feedback.append(f"**{icon} ã€Œ{original}ã€** â€” {status_text}")
            feedback.append("")
            regions = expr.get("regions_used")
            if regions:
                feedback.append(f"   ğŸ“ ä½¿ç”¨åœ°åŸŸ: {regions}")
                feedback.append("")
            note = expr.get("note", "")
            if note:
                feedback.append(f"   {note}")
                feedback.append("")
            alternatives = expr.get("alternatives", [])
            if alternatives:
                feedback.append("   **ä»£æ›¿è¡¨ç¾:**")
                for alt in alternatives:
                    region = alt.get("region", "")
                    formality = alt.get("formality", "")
                    formality_ja = {"formal": "ãƒ•ã‚©ãƒ¼ãƒãƒ«", "neutral": "æ™®é€š", "informal": "ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«"}.get(formality, formality)
                    feedback.append(f"   - \"{alt.get('expression', '')}\" ({region}, {formality_ja})")
                feedback.append("")
            rec = expr.get("recommendation", "")
            if rec:
                feedback.append(f"   ğŸ’¡ {rec}")
                feedback.append("")

    grammar = eval_result.get("grammar_feedback", [])
    if grammar:
        errors = [g for g in grammar if g.get("is_error")]
        regional = [g for g in grammar if g.get("is_regional_variant") and not g.get("is_error")]
        if errors:
            feedback.append("---")
            feedback.append("### âœï¸ æ–‡æ³•ã®ä¿®æ­£ç‚¹")
            feedback.append("")
            for g in errors:
                feedback.append(f"- âŒ {g.get('original', '')}")
                feedback.append(f"  â†’ âœ… **{g.get('correction', '')}**")
                feedback.append(f"  - {g.get('explanation', '')}")
                feedback.append("")
        if regional:
            feedback.append("---")
            feedback.append("### ğŸŒ åœ°åŸŸã«ã‚ˆã‚‹æ–‡æ³•ã®é•ã„")
            feedback.append("")
            for g in regional:
                feedback.append(f"- ã€Œ{g.get('original', '')}ã€")
                feedback.append(f"  - {g.get('explanation', '')}")
                regions = g.get("regions_where_acceptable", "")
                if regions:
                    feedback.append(f"  - è¨±å®¹ã•ã‚Œã‚‹åœ°åŸŸ: {regions}")
                feedback.append("")

    vocab = eval_result.get("vocabulary_analysis", {})
    if vocab:
        feedback.append("---")
        feedback.append("### ğŸ“š èªå½™åˆ†æ")
        feedback.append("")
        feedback.append(f"**CEFRãƒ¬ãƒ™ãƒ«: {vocab.get('cefr_level', 'N/A')}**")
        feedback.append("")
        if vocab.get("strengths"):
            feedback.append(f"âœ… **è‰¯ã„ç‚¹:** {vocab.get('strengths')}")
            feedback.append("")
        if vocab.get("suggestions"):
            feedback.append(f"ğŸ’¡ **ææ¡ˆ:** {vocab.get('suggestions')}")
            feedback.append("")
        academic = vocab.get("academic_words_used", [])
        if academic:
            feedback.append(f"ğŸ“– ä½¿ç”¨ã•ã‚ŒãŸã‚¢ã‚«ãƒ‡ãƒŸãƒƒã‚¯ãªèªå½™: {', '.join(academic)}")
            feedback.append("")

    content = eval_result.get("content_analysis", {})
    if content:
        feedback.append("---")
        feedback.append("### ğŸ’­ å†…å®¹åˆ†æ")
        feedback.append("")
        if content.get("strengths"):
            feedback.append(f"âœ… **è‰¯ã„ç‚¹:** {content.get('strengths')}")
            feedback.append("")
        if content.get("suggestions"):
            feedback.append(f"ğŸ’¡ **æ”¹å–„ç‚¹:** {content.get('suggestions')}")
            feedback.append("")

    cultural = eval_result.get("cultural_notes", [])
    if cultural:
        feedback.append("---")
        feedback.append("### ğŸ­ æ–‡åŒ–çš„ãªè£œè¶³")
        feedback.append("")
        for note in cultural:
            feedback.append(f"- **{note.get('topic', '')}**: {note.get('note', '')}")
        feedback.append("")

    enhanced = eval_result.get("enhanced_version", {})
    if enhanced and enhanced.get("text"):
        feedback.append("---")
        feedback.append("### âœ¨ å›½éš›çš„ã«é€šã˜ã‚„ã™ã„è¡¨ç¾ä¾‹")
        feedback.append("")
        feedback.append(f"> {enhanced.get('text', '')}")
        feedback.append("")
        if enhanced.get("changes_made"):
            feedback.append(f"ğŸ“ å¤‰æ›´ç‚¹: {enhanced.get('changes_made')}")
            feedback.append("")
        feedback.append("â€» ã“ã‚Œã¯ä¸€ä¾‹ã§ã™ã€‚ã‚ãªãŸã®å€‹æ€§ã‚„æ„å›³ã‚’å„ªå…ˆã—ã¦ãã ã•ã„ã€‚")
        feedback.append("")

    overall = eval_result.get("overall_feedback", "")
    if overall:
        feedback.append("---")
        feedback.append("### ğŸ“‹ ç·åˆãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯")
        feedback.append("")
        feedback.append(overall)
        feedback.append("")

    return "\n".join(feedback)

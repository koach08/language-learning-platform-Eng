import streamlit as st
import requests
import subprocess
import tempfile
import os
import math
import json
import base64

def extract_audio_from_video(video_path, output_path):
    """å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰éŸ³å£°ã‚’æŠ½å‡º"""
    cmd = [
        'ffmpeg', '-y', '-i', video_path,
        '-vn',  # æ˜ åƒã‚’ç„¡è¦–
        '-ar', '16000', '-ac', '1', '-acodec', 'pcm_s16le',
        output_path
    ]
    subprocess.run(cmd, capture_output=True, timeout=180)


def split_audio(wav_path, chunk_seconds=30):
    """éŸ³å£°ã‚’æŒ‡å®šç§’æ•°ã”ã¨ã«åˆ†å‰²"""
    chunks = []
    
    cmd = ['ffprobe', '-v', 'error', '-show_entries', 'format=duration', 
           '-of', 'default=noprint_wrappers=1:nokey=1', wav_path]
    result = subprocess.run(cmd, capture_output=True, text=True)
    duration = float(result.stdout.strip())
    
    num_chunks = math.ceil(duration / chunk_seconds)
    
    for i in range(num_chunks):
        start = i * chunk_seconds
        chunk_path = f"{wav_path}_chunk{i}.wav"
        
        cmd = [
            'ffmpeg', '-y', '-i', wav_path,
            '-ss', str(start), '-t', str(chunk_seconds),
            '-ar', '16000', '-ac', '1', '-acodec', 'pcm_s16le',
            chunk_path
        ]
        subprocess.run(cmd, capture_output=True, timeout=60)
        
        with open(chunk_path, 'rb') as f:
            chunks.append(f.read())
        
        os.unlink(chunk_path)
    
    return chunks, duration


def evaluate_chunk_simple(audio_data, api_key, region):
    """ã‚·ãƒ³ãƒ—ãƒ«ãªéŸ³å£°èªè­˜"""
    
    url = f"https://{region}.stt.speech.microsoft.com/speech/recognition/conversation/cognitiveservices/v1"
    
    params = {"language": "en-US", "format": "detailed"}
    
    headers = {
        "Ocp-Apim-Subscription-Key": api_key,
        "Content-Type": "audio/wav; codecs=audio/pcm; samplerate=16000",
        "Accept": "application/json"
    }
    
    try:
        response = requests.post(url, params=params, headers=headers, data=audio_data, timeout=90)
        
        if response.status_code == 200:
            result = response.json()
            
            recognized_text = result.get("DisplayText", "")
            nbest = result.get("NBest", [])
            
            if nbest:
                confidence = nbest[0].get("Confidence", 0)
            else:
                confidence = 0
            
            return {
                "text": recognized_text,
                "confidence": confidence,
                "raw": result
            }
        else:
            return {"text": "", "confidence": 0, "raw": None}
    except Exception as e:
        return {"text": "", "confidence": 0, "raw": None}


def evaluate_pronunciation(audio_file, reference_text):
    """Azure Speech APIã§ç™ºéŸ³ã‚’è©•ä¾¡ï¼ˆé•·ã„éŸ³å£°ãƒ»å‹•ç”»å¯¾å¿œï¼‰"""
    
    api_key = st.secrets["azure_speech"]["api_key"]
    region = st.secrets["azure_speech"]["region"]
    
    file_name = audio_file.name.lower()
    suffix = '.' + file_name.split('.')[-1]
    
    # å¯¾å¿œå½¢å¼ãƒã‚§ãƒƒã‚¯
    supported_audio = ['.wav', '.mp3', '.m4a']
    supported_video = ['.mp4', '.mov', '.webm', '.avi']
    
    is_video = suffix in supported_video
    
    try:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp_in:
            tmp_in.write(audio_file.read())
            tmp_in_path = tmp_in.name
        
        wav_path = tmp_in_path.replace(suffix, '_converted.wav')
        
        if is_video:
            # å‹•ç”»ã‹ã‚‰éŸ³å£°ã‚’æŠ½å‡º
            st.info("ğŸ¬ å‹•ç”»ã‹ã‚‰éŸ³å£°ã‚’æŠ½å‡ºä¸­...")
            extract_audio_from_video(tmp_in_path, wav_path)
        else:
            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’WAVã«å¤‰æ›
            cmd = [
                'ffmpeg', '-y', '-i', tmp_in_path,
                '-ar', '16000', '-ac', '1', '-acodec', 'pcm_s16le',
                wav_path
            ]
            subprocess.run(cmd, capture_output=True, timeout=120)
        
        os.unlink(tmp_in_path)
        
        # éŸ³å£°ã‚’åˆ†å‰²
        chunks, duration = split_audio(wav_path, chunk_seconds=30)
        os.unlink(wav_path)
        
        st.info(f"ğŸ“Š éŸ³å£°é•·: {duration:.1f}ç§’ / {len(chunks)}ãƒãƒ£ãƒ³ã‚¯ã§åˆ†æä¸­...")
        
        all_text = []
        all_confidence = []
        
        progress_bar = st.progress(0)
        for i, chunk in enumerate(chunks):
            result = evaluate_chunk_simple(chunk, api_key, region)
            if result["text"]:
                all_text.append(result["text"])
            if result["confidence"] > 0:
                all_confidence.append(result["confidence"])
            progress_bar.progress((i + 1) / len(chunks))
        
        # çµæœã‚’çµ±åˆ
        recognized_text = " ".join(all_text)
        
        if all_confidence:
            avg_confidence = sum(all_confidence) / len(all_confidence)
        else:
            avg_confidence = 0.7 if recognized_text else 0.3
        
        base_score = int(avg_confidence * 100)
        
        if reference_text:
            ref_words = len(reference_text.split())
            rec_words = len(recognized_text.split())
            completeness = min(100, int((rec_words / max(ref_words, 1)) * 100))
        else:
            completeness = 80 if recognized_text else 50
        
        overall = int((base_score * 0.7) + (completeness * 0.3))
        
        return {
            "success": True,
            "recognized_text": recognized_text,
            "duration": duration,
            "scores": {
                "overall": overall,
                "accuracy": base_score,
                "fluency": max(50, base_score - 5),
                "completeness": completeness,
                "prosody": max(50, base_score - 10)
            },
            "problem_words": [],
            "problem_phonemes": [],
            "intelligibility": get_intelligibility(base_score, base_score, base_score)
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }


def get_intelligibility(accuracy, fluency, prosody):
    """é€šã˜ã‚„ã™ã•ã‚’åˆ¤å®š"""
    
    weighted_score = (accuracy * 0.4) + (fluency * 0.4) + (prosody * 0.2)
    
    if weighted_score >= 75:
        return {
            "level": "é«˜ã„",
            "score": weighted_score,
            "description": "å›½éš›çš„ãªãƒ“ã‚¸ãƒã‚¹ã‚„å­¦è¡“ã®å ´ã§å•é¡Œãªãé€šã˜ã‚‹ãƒ¬ãƒ™ãƒ«ã§ã™ã€‚",
            "detail": "å¤šæ§˜ãªè‹±èªè©±è€…ã«ç†è§£ã•ã‚Œã‚„ã™ã„ç™ºéŸ³ã§ã™ã€‚",
            "icon": "ğŸŸ¢"
        }
    elif weighted_score >= 55:
        return {
            "level": "ä¸­ç¨‹åº¦",
            "score": weighted_score,
            "description": "æ—¥å¸¸ä¼šè©±ã‚„ä¸€èˆ¬çš„ãªã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯ååˆ†é€šã˜ã¾ã™ã€‚",
            "detail": "æ–‡è„ˆãŒã‚ã‚Œã°å•é¡Œãªãç†è§£ã•ã‚Œã¾ã™ã€‚",
            "icon": "ğŸŸ¡"
        }
    elif weighted_score >= 35:
        return {
            "level": "ã‚„ã‚„ä½ã„",
            "score": weighted_score,
            "description": "èãæ‰‹ãŒæ³¨æ„æ·±ãèã‘ã°ç†è§£ã§ãã‚‹ãƒ¬ãƒ™ãƒ«ã§ã™ã€‚",
            "detail": "ã‚†ã£ãã‚Šè©±ã™ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å¼·èª¿ã™ã‚‹ãªã©ã®å·¥å¤«ã§æ”¹å–„ã§ãã¾ã™ã€‚",
            "icon": "ğŸŸ "
        }
    else:
        return {
            "level": "è¦ç·´ç¿’",
            "score": weighted_score,
            "description": "ç†è§£ãŒå›°é›£ãªå ´åˆãŒã‚ã‚Šã¾ã™ã€‚",
            "detail": "åŸºç¤çš„ãªç™ºéŸ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç·´ç¿’ãŒåŠ¹æœçš„ã§ã™ã€‚",
            "icon": "ğŸ”´"
        }


def get_feedback(scores, problem_words, problem_phonemes, reference_text, duration=0):
    """è©³ç´°ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆ"""
    
    feedback = []
    
    overall = scores.get("overall", 0)
    accuracy = scores.get("accuracy", 0)
    fluency = scores.get("fluency", 0)
    prosody = scores.get("prosody", 0)
    completeness = scores.get("completeness", 0)
    
    if overall >= 85:
        level = "C1"
    elif overall >= 70:
        level = "B2"
    elif overall >= 55:
        level = "B1"
    elif overall >= 40:
        level = "A2"
    else:
        level = "A1"
    
    feedback.append("## ğŸ“‹ è©³ç´°ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯")
    feedback.append("")
    
    feedback.append("### ğŸŒ é€šã˜ã‚„ã™ã•ï¼ˆIntelligibilityï¼‰")
    feedback.append("")
    feedback.append("**æœ€ã‚‚é‡è¦ãªæŒ‡æ¨™ã§ã™ã€‚** ã€Œãƒã‚¤ãƒ†ã‚£ãƒ–ã®ã‚ˆã†ãªç™ºéŸ³ã€ã§ã¯ãªãã€ã€Œä¸–ç•Œä¸­ã®è‹±èªè©±è€…ã«é€šã˜ã‚‹ã‹ã€ã‚’è©•ä¾¡ã—ã¦ã„ã¾ã™ã€‚")
    feedback.append("")
    
    intelligibility = get_intelligibility(accuracy, fluency, prosody)
    feedback.append(f"{intelligibility['icon']} **{intelligibility['level']}** ({intelligibility['score']:.0f}/100)")
    feedback.append("")
    feedback.append(f"{intelligibility['description']}")
    feedback.append("")
    
    feedback.append("---")
    feedback.append("### ğŸ“Š é …ç›®åˆ¥ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯")
    feedback.append("")
    
    feedback.append(f"**1. ç™ºéŸ³ã®æ˜ç­ã•: {accuracy}/100**")
    if accuracy >= 80:
        feedback.append("   - âœ… å€‹ã€…ã®éŸ³ãŒã¯ã£ãã‚Šã¨èãå–ã‚Œã¾ã™ã€‚")
    elif accuracy >= 60:
        feedback.append("   - ğŸ“ å…¨ä½“çš„ã«èãå–ã‚Œã¾ã™ã€‚ä¸€éƒ¨ã®éŸ³ã‚’ã‚ˆã‚Šæ˜ç­ã«ã™ã‚‹ã¨è‰¯ã„ã§ã—ã‚‡ã†ã€‚")
    else:
        feedback.append("   - âš ï¸ ã„ãã¤ã‹ã®éŸ³ãŒèãå–ã‚Šã«ãã„çŠ¶æ…‹ã§ã™ã€‚")
    feedback.append("")
    
    feedback.append(f"**2. æµæš¢ã•: {fluency}/100**")
    if fluency >= 80:
        feedback.append("   - âœ… è‡ªç„¶ãªãƒšãƒ¼ã‚¹ã§è©±ã›ã¦ã„ã¾ã™ã€‚")
    elif fluency >= 60:
        feedback.append("   - ğŸ“ æ¦‚ã­ã‚¹ãƒ ãƒ¼ã‚ºã§ã™ã€‚æ„å‘³ã®ã¾ã¨ã¾ã‚Šã§åŒºåˆ‡ã‚‹ç·´ç¿’ãŒåŠ¹æœçš„ã§ã™ã€‚")
    else:
        feedback.append("   - âš ï¸ ãƒãƒ¼ã‚ºã‚„é€”åˆ‡ã‚ŒãŒç›®ç«‹ã¡ã¾ã™ã€‚çŸ­ã„æ–‡ã‹ã‚‰ç·´ç¿’ã—ã¾ã—ã‚‡ã†ã€‚")
    feedback.append("")
    
    feedback.append(f"**3. ã‚¤ãƒ³ãƒˆãƒãƒ¼ã‚·ãƒ§ãƒ³: {prosody}/100**")
    feedback.append("   â„¹ï¸ æ³¨æ„: ã‚¤ãƒ³ãƒˆãƒãƒ¼ã‚·ãƒ§ãƒ³ã¯åœ°åŸŸã«ã‚ˆã£ã¦ç•°ãªã‚Šã¾ã™ã€‚ã©ã®åœ°åŸŸã®è‹±èªã‚‚ã€Œæ­£ã—ã„ã€è‹±èªã§ã™ã€‚")
    feedback.append("")
    
    feedback.append("---")
    feedback.append("### ğŸ“š ç·´ç¿’ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹")
    feedback.append("")
    
    if accuracy < 70:
        feedback.append("**1. ç™ºéŸ³ç·´ç¿’**")
        feedback.append("   - è¾æ›¸ã‚µã‚¤ãƒˆã§ç™ºéŸ³ã‚’ç¢ºèªã—ã€çœŸä¼¼ã‚‹ç·´ç¿’ã‚’ã—ã¾ã—ã‚‡ã†")
        feedback.append("")
    
    if fluency < 70:
        feedback.append("**2. ãƒãƒ£ãƒ³ã‚¯èª­ã¿ç·´ç¿’**")
        feedback.append("   - æ–‡ã‚’æ„å‘³ã®ã¾ã¨ã¾ã‚Šã§åŒºåˆ‡ã£ã¦èª­ã‚€ç·´ç¿’ã‚’ã—ã¾ã—ã‚‡ã†")
        feedback.append("")
    
    feedback.append("**ç¶™ç¶šãŒæœ€ã‚‚é‡è¦ã§ã™** - æ¯æ—¥10åˆ†ã®ç·´ç¿’ãŒåŠ¹æœçš„ã§ã™")
    feedback.append("")
    
    test_scores = convert_to_test_scores(overall)
    feedback.append("---")
    feedback.append("### ğŸ“ˆ å‚è€ƒ: æ¤œå®šã‚¹ã‚³ã‚¢æ›ç®—ï¼ˆç›®å®‰ï¼‰")
    feedback.append("")
    feedback.append(f"| æ¤œå®š | æ›ç®—ã‚¹ã‚³ã‚¢ |")
    feedback.append(f"|------|-----------|")
    feedback.append(f"| CEFR | {test_scores['CEFR']} |")
    feedback.append(f"| TOEFL iBT Speaking | {test_scores['TOEFL_iBT_Speaking']}/30 |")
    feedback.append(f"| IELTS Speaking | {test_scores['IELTS_Speaking']} |")
    feedback.append(f"| è‹±æ¤œ | {test_scores['Eiken']}ç›¸å½“ |")
    feedback.append("")
    
    return {
        "cefr_level": level,
        "feedback": "\n".join(feedback)
    }


def convert_to_test_scores(overall_score):
    """å„ç¨®æ¤œå®šã‚¹ã‚³ã‚¢ã«æ›ç®—"""
    
    toefl_ibt = min(30, max(0, int(overall_score * 0.28)))
    ielts = min(9.0, max(0, round(overall_score / 100 * 8.5, 1)))
    
    return {
        "CEFR": score_to_cefr(overall_score),
        "TOEFL_iBT_Speaking": toefl_ibt,
        "IELTS_Speaking": ielts,
        "Eiken": score_to_eiken(overall_score)
    }


def score_to_cefr(score):
    if score >= 85: return "C1"
    elif score >= 70: return "B2"
    elif score >= 55: return "B1"
    elif score >= 40: return "A2"
    else: return "A1"


def score_to_eiken(score):
    if score >= 85: return "1ç´š"
    elif score >= 75: return "æº–1ç´š"
    elif score >= 60: return "2ç´š"
    elif score >= 45: return "æº–2ç´š"
    elif score >= 30: return "3ç´š"
    else: return "4-5ç´š"

"""
è‡ªç„¶ãªéŸ³å£°åˆæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« (Natural TTS)

å„ªå…ˆé †ä½:
1. Edge TTS (ç„¡æ–™ã€é«˜å“è³ªã€Microsoft Neural Voices)
2. OpenAI TTS (é«˜å“è³ªã€APIèª²é‡‘ã‚ã‚Š)
3. Web Speech API (ãƒ–ãƒ©ã‚¦ã‚¶å†…è”µã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯)
"""

import streamlit as st
import base64
import asyncio
import os
import tempfile
import hashlib


# ===== éŸ³å£°è¨­å®š =====

VOICE_OPTIONS = {
    "ã‚¢ãƒ¡ãƒªã‚«è‹±èª (å¥³æ€§)": {
        "edge": "en-US-JennyNeural",
        "openai": "nova",
        "lang": "en-US",
        "label": "US Female (Jenny)",
    },
    "ã‚¢ãƒ¡ãƒªã‚«è‹±èª (ç”·æ€§)": {
        "edge": "en-US-GuyNeural",
        "openai": "onyx",
        "lang": "en-US",
        "label": "US Male (Guy)",
    },
    "ã‚¤ã‚®ãƒªã‚¹è‹±èª (å¥³æ€§)": {
        "edge": "en-GB-SoniaNeural",
        "openai": "shimmer",
        "lang": "en-GB",
        "label": "UK Female (Sonia)",
    },
    "ã‚¤ã‚®ãƒªã‚¹è‹±èª (ç”·æ€§)": {
        "edge": "en-GB-RyanNeural",
        "openai": "echo",
        "lang": "en-GB",
        "label": "UK Male (Ryan)",
    },
    "ã‚ªãƒ¼ã‚¹ãƒˆãƒ©ãƒªã‚¢è‹±èª (å¥³æ€§)": {
        "edge": "en-AU-NatashaNeural",
        "openai": "nova",
        "lang": "en-AU",
        "label": "AU Female (Natasha)",
    },
    "ã‚«ãƒŠãƒ€è‹±èª (å¥³æ€§)": {
        "edge": "en-CA-ClaraNeural",
        "openai": "alloy",
        "lang": "en-CA",
        "label": "CA Female (Clara)",
    },
}

DEFAULT_VOICE = "ã‚¢ãƒ¡ãƒªã‚«è‹±èª (å¥³æ€§)"


# ===== ã‚­ãƒ£ãƒƒã‚·ãƒ¥ =====

def _get_cache_key(text, voice, speed):
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ç”Ÿæˆ"""
    raw = f"{text[:500]}_{voice}_{speed}"
    return hashlib.md5(raw.encode()).hexdigest()


def _get_from_cache(cache_key):
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—"""
    cache = st.session_state.get('tts_cache', {})
    return cache.get(cache_key)


def _save_to_cache(cache_key, audio_data):
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ï¼ˆæœ€å¤§20ä»¶ï¼‰"""
    if 'tts_cache' not in st.session_state:
        st.session_state.tts_cache = {}
    
    cache = st.session_state.tts_cache
    
    # å¤ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤
    if len(cache) >= 20:
        oldest = list(cache.keys())[0]
        del cache[oldest]
    
    cache[cache_key] = audio_data


# ===== Edge TTS (ãƒ¡ã‚¤ãƒ³) =====

def _generate_edge_tts(text, voice_key=DEFAULT_VOICE, speed=1.0):
    """Edge TTSã§éŸ³å£°ç”Ÿæˆï¼ˆç„¡æ–™ãƒ»é«˜å“è³ªï¼‰"""
    try:
        import edge_tts
    except ImportError:
        return None
    
    voice_config = VOICE_OPTIONS.get(voice_key, VOICE_OPTIONS[DEFAULT_VOICE])
    voice_name = voice_config['edge']
    
    # é€Ÿåº¦ã‚’Edge TTSå½¢å¼ã«å¤‰æ› (e.g., "+20%" or "-10%")
    speed_pct = int((speed - 1.0) * 100)
    rate_str = f"+{speed_pct}%" if speed_pct >= 0 else f"{speed_pct}%"
    
    async def _generate():
        communicate = edge_tts.Communicate(text, voice_name, rate=rate_str)
        
        with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as tmp:
            tmp_path = tmp.name
        
        await communicate.save(tmp_path)
        
        with open(tmp_path, 'rb') as f:
            audio_data = f.read()
        
        os.unlink(tmp_path)
        return audio_data
    
    try:
        # asyncio ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—å‡¦ç†
        try:
            loop = asyncio.get_event_loop()
            if loop.is_running():
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(asyncio.run, _generate())
                    return future.result(timeout=30)
            else:
                return loop.run_until_complete(_generate())
        except RuntimeError:
            return asyncio.run(_generate())
    
    except Exception as e:
        st.warning(f"Edge TTS error: {e}")
        return None


# ===== OpenAI TTS (ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—) =====

def _generate_openai_tts(text, voice_key=DEFAULT_VOICE, speed=1.0):
    """OpenAI TTSã§éŸ³å£°ç”Ÿæˆï¼ˆé«˜å“è³ªãƒ»æœ‰æ–™ï¼‰"""
    try:
        from openai import OpenAI
        client = OpenAI(api_key=st.secrets["openai"]["api_key"])
    except Exception:
        return None
    
    voice_config = VOICE_OPTIONS.get(voice_key, VOICE_OPTIONS[DEFAULT_VOICE])
    voice_name = voice_config['openai']
    
    try:
        response = client.audio.speech.create(
            model="tts-1-hd",
            voice=voice_name,
            input=text[:4096],
            speed=speed
        )
        return response.content
    except Exception as e:
        st.warning(f"OpenAI TTS error: {e}")
        return None


# ===== Web Speech API (æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯) =====

def _play_web_speech_api(text, voice_key=DEFAULT_VOICE, speed=1.0):
    """ãƒ–ãƒ©ã‚¦ã‚¶å†…è”µWeb Speech APIã§å†ç”Ÿ"""
    voice_config = VOICE_OPTIONS.get(voice_key, VOICE_OPTIONS[DEFAULT_VOICE])
    lang = voice_config['lang']
    
    escaped = text.replace("'", "\\'").replace("\n", " ").replace('"', '\\"')
    
    js = f"""
    <script>
    (function() {{
        window.speechSynthesis.cancel();
        setTimeout(function() {{
            const u = new SpeechSynthesisUtterance("{escaped}");
            u.lang = "{lang}";
            u.rate = {speed};
            window.speechSynthesis.speak(u);
        }}, 100);
    }})();
    </script>
    """
    st.components.v1.html(js, height=0)
    return True


# ===== ãƒ¡ã‚¤ãƒ³é–¢æ•° =====

def generate_natural_audio(text, voice_key=DEFAULT_VOICE, speed=1.0, use_cache=True):
    """
    è‡ªç„¶ãªéŸ³å£°ã‚’ç”Ÿæˆï¼ˆãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™ï¼‰
    
    å„ªå…ˆé †ä½: Edge TTS â†’ OpenAI TTS â†’ None
    """
    if not text or not text.strip():
        return None
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
    if use_cache:
        cache_key = _get_cache_key(text, voice_key, speed)
        cached = _get_from_cache(cache_key)
        if cached:
            return cached
    
    # 1. Edge TTS
    audio = _generate_edge_tts(text, voice_key, speed)
    
    # 2. OpenAI TTS (EdgeãŒä½¿ãˆãªã„å ´åˆ)
    if audio is None:
        audio = _generate_openai_tts(text, voice_key, speed)
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
    if audio and use_cache:
        _save_to_cache(cache_key, audio)
    
    return audio


def play_natural_tts(text, voice_key=DEFAULT_VOICE, speed=1.0, use_cache=True):
    """
    è‡ªç„¶ãªéŸ³å£°ã§å†ç”Ÿï¼ˆUIã«åŸ‹ã‚è¾¼ã¿ï¼‰
    
    å„ªå…ˆé †ä½: Edge TTS â†’ OpenAI TTS â†’ Web Speech API
    """
    if not text or not text.strip():
        return
    
    audio = generate_natural_audio(text, voice_key, speed, use_cache)
    
    if audio:
        b64 = base64.b64encode(audio).decode()
        audio_html = f"""
        <audio controls autoplay style="width:100%">
            <source src="data:audio/mp3;base64,{b64}" type="audio/mp3">
        </audio>
        """
        st.markdown(audio_html, unsafe_allow_html=True)
    else:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        _play_web_speech_api(text, voice_key, speed)
        st.caption("âš ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯éŸ³å£°ï¼ˆãƒ–ãƒ©ã‚¦ã‚¶å†…è”µï¼‰ã‚’ä½¿ç”¨ä¸­")


def stop_audio():
    """éŸ³å£°åœæ­¢"""
    js = """
    <script>
    (function() {
        window.speechSynthesis.cancel();
        document.querySelectorAll('audio').forEach(a => { a.pause(); a.currentTime = 0; });
    })();
    </script>
    """
    st.components.v1.html(js, height=0)


# ===== UI ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ =====

def show_tts_player(text, key_prefix="tts", show_voice_select=True, default_voice=DEFAULT_VOICE):
    """TTSå†ç”Ÿãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼UI"""
    
    cols = st.columns([2, 2, 1, 1] if show_voice_select else [2, 1, 1])
    col_idx = 0
    
    if show_voice_select:
        with cols[col_idx]:
            voice = st.selectbox(
                "éŸ³å£°",
                list(VOICE_OPTIONS.keys()),
                index=list(VOICE_OPTIONS.keys()).index(default_voice),
                key=f"{key_prefix}_voice"
            )
        col_idx += 1
    else:
        voice = default_voice
    
    with cols[col_idx]:
        speed = st.select_slider(
            "é€Ÿåº¦",
            options=[0.5, 0.75, 0.85, 1.0, 1.15, 1.25, 1.5],
            value=1.0,
            format_func=lambda x: f"{x}x",
            key=f"{key_prefix}_speed"
        )
    col_idx += 1
    
    with cols[col_idx]:
        if st.button("ğŸ”Š å†ç”Ÿ", key=f"{key_prefix}_play", use_container_width=True):
            with st.spinner("éŸ³å£°ã‚’ç”Ÿæˆä¸­..."):
                play_natural_tts(text, voice, speed)
    col_idx += 1
    
    if col_idx < len(cols):
        with cols[col_idx]:
            if st.button("â¹ï¸ åœæ­¢", key=f"{key_prefix}_stop", use_container_width=True):
                stop_audio()
    
    # éŸ³å£°å“è³ªã®æ³¨è¨˜
    show_tts_quality_note()
    
    return voice, speed


def show_tts_quality_note():
    """TTSéŸ³å£°å“è³ªã«é–¢ã™ã‚‹å°ã•ãªæ³¨è¨˜"""
    st.caption(
        "ğŸ’¡ ã‚ˆã‚Šè‡ªç„¶ãªéŸ³å£°ã§è´ããŸã„å ´åˆã¯ "
        "[ğŸ“˜ ä½¿ã„æ–¹ã‚¬ã‚¤ãƒ‰ â†’ éŸ³å£°ãƒ„ãƒ¼ãƒ«] ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚"
    )


def show_word_audio_button(word, key_prefix="word"):
    """å˜èªã®éŸ³å£°å†ç”Ÿãƒœã‚¿ãƒ³ï¼ˆå°ã•ã‚ï¼‰"""
    if st.button(f"ğŸ”Š {word}", key=f"{key_prefix}_{word}"):
        with st.spinner(""):
            play_natural_tts(word, DEFAULT_VOICE, 0.85)
